{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "「Lab2-1b.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YooYooo/github/blob/main/%E3%80%8CLab2_1b_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHKdD1qU62DF"
      },
      "source": [
        "# 實驗一：房價預測模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnhWEyv-62DH"
      },
      "source": [
        "### Import必要套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abDmAO862DI"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRPHVV-D-FwS"
      },
      "source": [
        "## Step 1. 設定 Google Drive 連接 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjFZLoyA-I5K",
        "outputId": "683f7784-b644-4587-d60b-86e1ffebe6bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # 點擊網址，選擇 Google 帳號登入，然後將授權碼貼回輸入框中"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFx5kPLa-YCL"
      },
      "source": [
        "!ln -fs /content/gdrive/My\\ Drive/class/ /app  #執行一次就可，否則會有錯誤訊息"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keDyMyFSb-r8"
      },
      "source": [
        "### https://www.kaggle.com/shivachandel/kc-house-data\n",
        "### http://www.stodolkiewicz.com/2020/01/28/tensorflow-2-regression-on-the-boston-housing-dataset-part-2-keras-callbacks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ujBpka1cE8"
      },
      "source": [
        "### 步驟 2. 下載 cuDNN 檔案\n",
        "\n",
        "1. 申請 Nvidia 帳號，申請網址為 http://bit.ly/2qfpOPj\n",
        "2. 下載 `cudnn-10.0-linux-x64-v7.5.0.56.tgz`，下載網址為 \n",
        "下載 cuDNN 檔案。下載網址為：http://bit.ly/2qfpOPj\n",
        "3. 將下載的檔案 `cudnn-10.0-linux-x64-v7.5.0.56.tgz` 放到 google drive 的 `Colab Notebooks/cuDNN/` 目錄下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1uWe9rV1i1p",
        "outputId": "090efdc7-539e-47e5-ca0f-20939a358198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tar -xzvf /app/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "\n",
        "# 檢查是否安裝成功\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda/include/cudnn.h\n",
            "cuda/NVIDIA_SLA_cuDNN_Support.txt\n",
            "cuda/lib64/libcudnn.so\n",
            "cuda/lib64/libcudnn.so.7\n",
            "cuda/lib64/libcudnn.so.7.5.0\n",
            "cuda/lib64/libcudnn_static.a\n",
            "#define CUDNN_MAJOR 7\n",
            "#define CUDNN_MINOR 5\n",
            "#define CUDNN_PATCHLEVEL 0\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "#include \"driver_types.h\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0i2MFvo62DN"
      },
      "source": [
        "### 數據讀取並分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OCiPHM2K62DN",
        "outputId": "fce5f342-f11d-4224-a807-f8c2ca5c5f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = pd.read_csv(\"/app/kc_house_data.csv\")\n",
        "# 顯示dataset的形狀，共21613比資料，每一比資料有21種不同資訊。\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21613, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3on7lew62DS",
        "outputId": "67935228-d53d-4eda-b238-2b28a09f2179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 將顯示列數設定為25，不然會有部份資料無法顯示\n",
        "pd.options.display.max_columns = 25\n",
        "# head 會顯示前五行的數據\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
              "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
              "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
              "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
              "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
              "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
              "\n",
              "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
              "0      5650     1.0           0     0          3      7      1180.0   \n",
              "1      7242     2.0           0     0          3      7      2170.0   \n",
              "2     10000     1.0           0     0          3      6       770.0   \n",
              "3      5000     1.0           0     0          5      7      1050.0   \n",
              "4      8080     1.0           0     0          3      8      1680.0   \n",
              "\n",
              "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
              "0              0      1955             0    98178  47.5112 -122.257   \n",
              "1            400      1951          1991    98125  47.7210 -122.319   \n",
              "2              0      1933             0    98028  47.7379 -122.233   \n",
              "3            910      1965             0    98136  47.5208 -122.393   \n",
              "4              0      1987             0    98074  47.6168 -122.045   \n",
              "\n",
              "   sqft_living15  sqft_lot15  \n",
              "0           1340        5650  \n",
              "1           1690        7639  \n",
              "2           2720        8062  \n",
              "3           1360        5000  \n",
              "4           1800        7503  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZULEp-y62DW"
      },
      "source": [
        "各個數據的簡寫分別代表下面意思：\n",
        "- date：房屋出售日期。\n",
        "- price：房屋價格（目標）。\n",
        "- bedrooms：臥室數量。\n",
        "- bathrooms：浴室數量。\n",
        "- sqft_living：居住的坪數（平方英尺）。\n",
        "- sqft_lot：實際的坪數（平方英尺）。\n",
        "- floors：房屋總共樓層。\n",
        "- waterfront：海景房。\n",
        "- view：房屋是否看過。\n",
        "- condition：整體條件有多好。\n",
        "- grade：房屋的整體等級（根據King County評分系統）。\n",
        "- sqft_above：除了地下室外的坪數（平方英尺）。\n",
        "- sqft_basement：地下室的坪數（平方英尺）。\n",
        "- yr_built：房屋建造時間。\n",
        "- yr_renovated：何時重新裝修過（一些沒重新裝修過或是裝修紀錄沒被記錄到的數值都為0）。\n",
        "- zipcode：郵政編碼。\n",
        "- lat：緯度座標。\n",
        "- long：經度座標。\n",
        "- sqft_living15：2015年紀錄的居住坪數（可能是翻新的原因導致sqft_living15與sqft_living不同）。\n",
        "- sqft_lot15：2015年紀錄的實際坪數（可能是翻新的原因導致sqft_lot15與sqft_lot不同）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVWFc68N62DX"
      },
      "source": [
        "### 檢查資料的型態\n",
        "\n",
        "資料型態總共有五種：object(string),booleab, integer, float and categorical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21xrCehU62DY",
        "outputId": "1866b5f8-0148-4cc4-afc1-e08178c1d036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 int64\n",
              "date              object\n",
              "price            float64\n",
              "bedrooms           int64\n",
              "bathrooms        float64\n",
              "sqft_living        int64\n",
              "sqft_lot           int64\n",
              "floors           float64\n",
              "waterfront         int64\n",
              "view               int64\n",
              "condition          int64\n",
              "grade              int64\n",
              "sqft_above       float64\n",
              "sqft_basement      int64\n",
              "yr_built           int64\n",
              "yr_renovated       int64\n",
              "zipcode            int64\n",
              "lat              float64\n",
              "long             float64\n",
              "sqft_living15      int64\n",
              "sqft_lot15         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90wPmfor62Dc"
      },
      "source": [
        "### 數據前處理\n",
        "轉換資料型態：\n",
        "因為數據集裡的date數據是字串（string）格式，而模型的輸入只接受數值格式，所以可以透過以下程式碼將其轉為數值，並分成年、月及日三種數據。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-KeJgIW62De",
        "outputId": "1f871738-3a3c-4f88-8495-f54f0c7b3854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 將date日期拆為年、月和日並轉成數值\n",
        "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))\n",
        "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
        "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
        "\n",
        "# 刪除沒有用的數據，inplace則是將更新後的資料存回原本的地方\n",
        "data.drop(['id'], axis=\"columns\", inplace=True)\n",
        "data.drop(['date'], axis=\"columns\", inplace=True)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "      <td>2014</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "      <td>2014</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "      <td>2014</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  sqft_living  ...  sqft_lot15  year  month  day\n",
              "0  221900.0         3       1.00         1180  ...        5650  2014     10   13\n",
              "1  538000.0         3       2.25         2570  ...        7639  2014     12    9\n",
              "2  180000.0         2       1.00          770  ...        8062  2015      2   25\n",
              "3  604000.0         4       3.00         1960  ...        5000  2014     12    9\n",
              "4  510000.0         3       2.00         1680  ...        7503  2015      2   18\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ILOQaNA62Dj"
      },
      "source": [
        "分割數據集（Dataset）：將數據集切割成三個部份，訓練數據（Training data）、驗證數據（Validation data）和測試數據（Testing data）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij63xCTu62Dj"
      },
      "source": [
        "data_num = data.shape[0]\n",
        "# 取得一筆與data數量相同的亂數索引，主要目的是用於打散資料\n",
        "indexes = np.random.permutation(data_num)\n",
        "# 並將亂數索引值分為Train、validation和test分為，這裡的劃分比例為6:2:2\n",
        "train_indexes = indexes[:int(data_num *0.6)]\n",
        "val_indexes = indexes[int(data_num *0.6):int(data_num *0.8)]\n",
        "test_indexes = indexes[int(data_num *0.8):]\n",
        "# 透過索引值從data取出訓練資料、驗證資料和測試資料\n",
        "train_data = data.loc[train_indexes]\n",
        "val_data = data.loc[val_indexes]\n",
        "test_data = data.loc[test_indexes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OojnFm5-62Dn"
      },
      "source": [
        "### Normalization 正規化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RurfzID162Do"
      },
      "source": [
        "使用標準分數(Standard Score, 又稱z-score)將數據正規化，經過z-score正規化後數據的都會聚集在0附近， 標準差為1。 \n",
        "\n",
        "(x - 平均值) / 標準差"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qDtQMNKJ62Do"
      },
      "source": [
        "train_validation_data = pd.concat([train_data, val_data])\n",
        "mean = train_validation_data.mean()\n",
        "std = train_validation_data.std()\n",
        "\n",
        "train_data = (train_data - mean) / std\n",
        "val_data = (val_data - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mh9rTpB62Ds"
      },
      "source": [
        "### 建立Numpy array格式的訓練數據"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN5_H4Bh62Ds"
      },
      "source": [
        "x_train = np.array(train_data.drop('price', axis='columns'))\n",
        "y_train = np.array(train_data['price'])\n",
        "x_val = np.array(val_data.drop('price', axis='columns'))\n",
        "y_val = np.array(val_data['price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9z_JEa-62Dw"
      },
      "source": [
        "整理過後的資料共12967筆，且一筆資料有21種資訊(所以網路輸入必須為21)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWm5RX8262Dw",
        "outputId": "fa130ce5-d0f6-4b11-834a-4ca11b637f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.39484709, -1.44386865, -0.79934452,  0.14313455,  0.01186833,\n",
              "        -0.08837549, -0.30295239,  0.91729864, -2.26201882, -0.53892855,\n",
              "        -0.65506191, -0.88410837, -0.21188889, -0.85751385, -1.13280673,\n",
              "        -0.41735889, -0.93917586,  0.90422262, -0.69165158,  1.42585481,\n",
              "        -0.42169893],\n",
              "       [ 0.67654435,  0.50321156,  0.73183191, -0.07848369,  0.93620829,\n",
              "        -0.08837549, -0.30295239, -0.62491193,  1.14806972,  1.16775008,\n",
              "        -0.65506191,  1.4620905 , -0.21188889, -0.35396384, -0.64685602,\n",
              "         0.66228946,  0.47192638, -0.03387035, -0.69165158,  1.74741886,\n",
              "         0.73748873],\n",
              "       [-0.39484709, -0.47032854, -0.86450096, -0.0564291 , -0.91247163,\n",
              "        -0.08837549, -0.30295239,  0.91729864, -0.55697455, -0.61155318,\n",
              "        -0.65506191,  0.20398386, -0.21188889, -0.87616385, -0.99674053,\n",
              "         0.10825939, -0.44456271, -0.03843881,  1.44573105, -1.46822166,\n",
              "        -1.34904905],\n",
              "       [ 0.67654435,  0.50321156,  0.54722199, -0.00385714,  0.93620829,\n",
              "        -0.08837549, -0.30295239, -0.62491193,  1.14806972,  0.96198032,\n",
              "        -0.65506191,  0.95204727, -0.21188889, -0.48451385,  0.93482356,\n",
              "         0.8540691 ,  1.51934247, -0.08713277, -0.69165158,  1.42585481,\n",
              "        -0.30578016],\n",
              "       [ 0.67654435,  0.50321156,  0.87300421, -0.14439098,  0.93620829,\n",
              "        -0.08837549, -0.30295239, -0.62491193,  2.00059185,  1.32510343,\n",
              "        -0.65506191,  1.25807321, -0.21188889, -0.83886385,  0.89810729,\n",
              "         0.10825939,  0.95199209, -0.16816851, -0.69165158,  0.1395986 ,\n",
              "         1.78075762]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZD7vqBv62D0"
      },
      "source": [
        "### 建立並訓練網路模型\n",
        "\n",
        "這裡建構三層全連接層的網路架構，並且使用ReLU作為隱藏層的激活函數，而由於需得到線性輸出，故輸出層不使用任何激活函數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syzeGcExh10L",
        "outputId": "5cc3ffe7-c485-4e53-9015-ed0a6d17dc4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 建立一個Sequential型態的model\n",
        "model = keras.Sequential(name='model-1')\n",
        "# 第1層全連接層設為64個unit，將輸入形狀設定為(21, )，而實際上我們輸入的數據形狀為(batch_size, 21)\n",
        "model.add(layers.Dense(21, activation='relu', input_shape=(21,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# 最後一層全連接層設為1個unit\n",
        "model.add(layers.Dense(1))\n",
        "# 顯示網路模型架構\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model-1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 21)                462       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                1408      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 6,095\n",
            "Trainable params: 6,095\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9ZhzEg62D5"
      },
      "source": [
        "設定訓練使用的優化器、損失函數和指標函數："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfrX2uEC62D5"
      },
      "source": [
        "model.compile(keras.optimizers.Adam(0.001),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-585oEUi62D9"
      },
      "source": [
        "創建模型儲存目錄："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gxWwiYU62D9",
        "outputId": "3c8a0f63-37df-49c9-8445-277c8ab72700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_dir = '/app/lab2-logs/models/'\n",
        "%cd /app\n",
        "!rm -rf lab2-logs\n",
        "os.makedirs(model_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw7U2Cc262EA"
      },
      "source": [
        "設定回調函數："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk7CcQ1y62EE"
      },
      "source": [
        "訓練網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t7XYNN6dCQQ",
        "outputId": "0b08363d-a695-4ab6-f24b-e97463d0dcc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# TensorBoard回調函數會幫忙紀錄訓練資訊，並存成TensorBoard的紀錄檔\n",
        "log_dir = os.path.join('/app/lab2-logs', 'model-1')\n",
        "# patience: number of epochs that produced the monitored quantity with no improvement after which training will be stopped.\n",
        "# Simply speaking - If there is no improvement in mse on the test set after any 15 epochs -> stop the training procedure\n",
        "monitor_val_acc = EarlyStopping(monitor = 'val_loss', patience=15)\n",
        "\n",
        "# save the best model ( = lowest mse) to a file 'best_model.hdf5'\n",
        "modelCheckpoint = ModelCheckpoint(model_dir + '/Best-model-1.h5', save_best_only = True)\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "# pass the above callbacks to callbacks parameter\n",
        "history = model.fit(x_train, y_train, \n",
        "                batch_size=64,  # 批次大小設為64\n",
        "                epochs=300,  # 整個dataset訓練300遍\n",
        "                validation_data=(x_val, y_val), \n",
        "                callbacks=[monitor_val_acc, modelCheckpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9501 - mean_absolute_error: 0.6059 - val_loss: 0.8827 - val_mean_absolute_error: 0.6225\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0394 - mean_absolute_error: 0.6399 - val_loss: 0.8854 - val_mean_absolute_error: 0.6416\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0396 - mean_absolute_error: 0.6429 - val_loss: 0.8844 - val_mean_absolute_error: 0.6383\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0397 - mean_absolute_error: 0.6428 - val_loss: 0.8828 - val_mean_absolute_error: 0.6306\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0395 - mean_absolute_error: 0.6416 - val_loss: 0.8834 - val_mean_absolute_error: 0.6347\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0394 - mean_absolute_error: 0.6408 - val_loss: 0.8859 - val_mean_absolute_error: 0.6428\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0394 - mean_absolute_error: 0.6427 - val_loss: 0.8826 - val_mean_absolute_error: 0.6295\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0398 - mean_absolute_error: 0.6414 - val_loss: 0.8835 - val_mean_absolute_error: 0.6348\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 1.0392 - mean_absolute_error: 0.6420 - val_loss: 0.8829 - val_mean_absolute_error: 0.6315\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0392 - mean_absolute_error: 0.6410 - val_loss: 0.8846 - val_mean_absolute_error: 0.6390\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0394 - mean_absolute_error: 0.6422 - val_loss: 0.8832 - val_mean_absolute_error: 0.6332\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0392 - mean_absolute_error: 0.6416 - val_loss: 0.8841 - val_mean_absolute_error: 0.6371\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0393 - mean_absolute_error: 0.6419 - val_loss: 0.8840 - val_mean_absolute_error: 0.6369\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0392 - mean_absolute_error: 0.6410 - val_loss: 0.8844 - val_mean_absolute_error: 0.6384\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0392 - mean_absolute_error: 0.6423 - val_loss: 0.8836 - val_mean_absolute_error: 0.6353\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0393 - mean_absolute_error: 0.6428 - val_loss: 0.8829 - val_mean_absolute_error: 0.6317\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0392 - mean_absolute_error: 0.6411 - val_loss: 0.8833 - val_mean_absolute_error: 0.6337\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0393 - mean_absolute_error: 0.6419 - val_loss: 0.8844 - val_mean_absolute_error: 0.6386\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0391 - mean_absolute_error: 0.6419 - val_loss: 0.8833 - val_mean_absolute_error: 0.6341\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0389 - mean_absolute_error: 0.6449 - val_loss: 0.8826 - val_mean_absolute_error: 0.6285\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0393 - mean_absolute_error: 0.6404 - val_loss: 0.8829 - val_mean_absolute_error: 0.6315\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0391 - mean_absolute_error: 0.6406 - val_loss: 0.8835 - val_mean_absolute_error: 0.6348\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0390 - mean_absolute_error: 0.6408 - val_loss: 0.8836 - val_mean_absolute_error: 0.6355\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0391 - mean_absolute_error: 0.6428 - val_loss: 0.8834 - val_mean_absolute_error: 0.6346\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0391 - mean_absolute_error: 0.6423 - val_loss: 0.8832 - val_mean_absolute_error: 0.6332\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.6420 - val_loss: 0.8830 - val_mean_absolute_error: 0.6322\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0391 - mean_absolute_error: 0.6403 - val_loss: 0.8833 - val_mean_absolute_error: 0.6342\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.6423 - val_loss: 0.8833 - val_mean_absolute_error: 0.6341\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.6433 - val_loss: 0.8828 - val_mean_absolute_error: 0.6306\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0391 - mean_absolute_error: 0.6406 - val_loss: 0.8835 - val_mean_absolute_error: 0.6347\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0390 - mean_absolute_error: 0.6414 - val_loss: 0.8830 - val_mean_absolute_error: 0.6323\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0389 - mean_absolute_error: 0.6406 - val_loss: 0.8837 - val_mean_absolute_error: 0.6358\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.6430 - val_loss: 0.8831 - val_mean_absolute_error: 0.6327\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0391 - mean_absolute_error: 0.6419 - val_loss: 0.8833 - val_mean_absolute_error: 0.6338\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0390 - mean_absolute_error: 0.6416 - val_loss: 0.8831 - val_mean_absolute_error: 0.6330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ_FMopPggbr"
      },
      "source": [
        "### 原課本程式 (執行階段發生錯誤)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU7m_eSA62EI"
      },
      "source": [
        "### 訓練結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5GsNEQw62EJ",
        "outputId": "0fd099e6-559a-4277-ef79-24bde5843098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history.history.keys()  # 查看history儲存的資訊有哪些"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SVyhmqk62EN",
        "outputId": "97502e74-eb11-4bea-a7bf-e5fb5437e773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.ylim(0.02, 0.2)\n",
        "plt.title('Mean square error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbRVdb3v8fdHQBBEBcRSQKH0JILGwxLtqqRShlY+FAqmJh6LshzW6WGI1UkP6c3u6arXcUyl63MqcTCTWxppYWmFsTFEHlQQUTb4gCCIAir6vX/M36bFYu3Nnsjce234vMZYg7V+8zfn/s45Bvuz5/zN9ZuKCMzMzJprl9YuwMzM2hYHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFtgqQlkt6WtHdF+z8khaS+rVOZ2c7HwWFtyXPAmQ0fJB0KdG69clqXpPYFbluSdqloy/XziqzPWpeDw9qSO4Avln0+F7i9vIOkjpJ+KukFSS9LukHSbmlZN0m/kbRC0mvpfe+ydR+W9CNJf5G0VtLvK89wyvrundZfLWmVpEcaftFKGizp8bSNX0qaJOnytGyspEcrthWSDkzvP53Ool6XtFTSZWX9+qa+50t6Afhjav9XSQvSPk2TdEBjB1DSkZL+mup+QtKxFft/haS/AOuAD6Wf93VJC4GFqd+XJS1K+z1V0n4V+7JZf9vxODisLZkB7CGpv6R2wBjgFxV9rgT+BRgEHAj0An6Ylu0C3AIcAOwPrAf+q2L9LwDnAfsAuwLfaaSWbwP1QE/gA8D3gJC0K/BrspDrDvw38Pkc+/gmWTjuBXwauEDSqRV9Pg70Bz4l6ZT0sz+XankEuLvahiX1An4LXJ5q+w5wj6SeZd3OAcYBXYHnU9upwBHAIZKOB34MnAHsm/pMqvhRm/rn2G9rQxwc1tY0nHV8ElgALGtYIElkv/T+LSJWRcRa4H+SBQwRsTIi7omIdWnZFWS/hMvdEhHPRMR6YDJZAFXzDtkvzgMi4p2IeCSyid+OBDoA16T2KcDM5u5cRDwcEU9GxHsRMYcsBCprvCwi3kw1fhX4cUQsiIiNaX8HNXLWcTZwf0Tcn7b/IFAHnFTW59aImBcRGyPindT243Q81wNnATdHxOMR8RZwCfCxijGm8v62A3JwWFtzB9lZwVgqLlOR/cXdGZiVLsWsBn6X2pHUWdKNkp6X9DrwZ2CvdPbS4KWy9+uA3Rup4z+BRcDvJS2WND617wcsi81nD31+i7UbIekISdPT5bQ1ZMFQeblsadn7A4D/U7a/qwCRnWlVOgA4vaFv6n80WQBW23a1tv3K9yci3gBWVvy8atuwHYiDw9qUiHiebJD8JOBXFYtfJbv8NCAi9kqvPSOi4Zf/t4GPAEdExB7A8NSubahjbUR8OyI+BJwMfEvSCOBFoFc6+2mwf9n7Nykb0Jf0wYpN3wVMBfpExJ7ADVXqKw+lpcBXyvZ3r4jYLSL+WqXspcAdFX27RMSVjWy7WttysgBqqL8L0IOyM79GtmE7EAeHtUXnA8dHxJvljRHxHvBz4GpJ+0B2XV/Sp1KXrmTBslpSd+DSbS1A0mckHZgCYg3wLvAe8DdgI3CRpA6SPgcMK1v1CWCApEGSOgGXVWy6K7AqIjZIGkZ2dtWUG4BLJA1Ide0p6fRG+v4C+KykT0lqJ6mTpGPLbxBohruB81L9HckujT0WEUtybMPaOAeHtTkR8WxE1DWy+GKyS0gz0uWoh8jOMgCuAXYjOzOZQXYZa1sdlLb9BllY/CwipkfE22QD1WPJLhuNpuzMKCKeASakdRcCj26+Wb4GTJC0lmxQf3JTRUTEvcBPgElpf+cCJzbSdynQMJi+guwM5Lvk+D0QEQ8B/w7cQ3Z29WHSGJLtPOQHOZkVS9KtQH1E/KC1azHbHnzGYWZmuRQaHJJGSno6fVlofJXl35I0X9IcSX8ov4VQ0rmSFqbXuWXtQyU9mbZ5bcUgpJmZFaywS1XpFsdnyO63rye7l/3MiJhf1uc4soG1dZIuAI6NiNFp4LIOKJHdoTELGBoRr0n6O3AR8BhwP3BtRDxQyE6YmdkWijzjGAYsiojFacBwEtnA3CZpMHFd+jgDaLi741PAg+lLRK8BDwIjJe0L7BERM9J98reTfUvVzMxaSJGTkPVi8y8C1ZNNQ9CY84GGM4dq6/ZKr/oq7VuQNI7sW8R06dJl6MEHH5yndjOznd6sWbNejYiele01MXulpLPJLktVTq2wzSJiIjARoFQqRV1dY3dvmplZNZKqznpQ5KWqZUCfss+92fzbpQBI+gTwfeDkNPdNU+su45+XsxrdppmZFafI4JgJHCSpX5oxdAzZVAqbSBoM3EgWGq+ULZoGnKBsGuxuwAnAtIh4EXg9TQ0tssnu7itwH8zMrEJhl6oiYqOkC8lCoB3ZjJrzJE0A6iJiKtlEcbsD/53uqn0hIk6OiFWSfsQ/ZxWdEBGr0vuvAbeSfQP4Af45LmJmZi1gp/jmuMc4zHYc77zzDvX19WzYsKG1S9lhdOrUid69e9OhQ4fN2iXNiohSZf+aGBw3M2uu+vp6unbtSt++ffH3f9+/iGDlypXU19fTr1+/Zq3jKUfMrE3ZsGEDPXr0cGhsJ5Lo0aNHrjM4B4eZtTkOje0r7/F0cJiZWS4ODjOzHFavXs3Pfvaz3OuddNJJrF69uoCKWp6Dw8wsh8aCY+PGjU2ud//997PXXnsVVVaL8l1VZmY5jB8/nmeffZZBgwbRoUMHOnXqRLdu3Xjqqad45plnOPXUU1m6dCkbNmzgG9/4BuPGjQOgb9++1NXV8cYbb3DiiSdy9NFH89e//pVevXpx3333sdtuu7XynjWfg8PM2qz/+H/zmL/89e26zUP224NLPzug0eVXXnklc+fOZfbs2Tz88MN8+tOfZu7cuZtuZb355pvp3r0769ev5/DDD+fzn/88PXr02GwbCxcu5O677+bnP/85Z5xxBvfccw9nn332dt2PIjk4zMzeh2HDhm32/Ydrr72We++9F4ClS5eycOHCLYKjX79+DBo0CIChQ4eyZMmSFqt3e3BwmFmb1dSZQUvp0qXLpvcPP/wwDz30EH/729/o3Lkzxx57bNXvR3Ts2HHT+3bt2rF+/foWqXV78eC4mVkOXbt2Ze3atVWXrVmzhm7dutG5c2eeeuopZsyY0cLVtQyfcZiZ5dCjRw+OOuooBg4cyG677cYHPvCBTctGjhzJDTfcQP/+/fnIRz7CkUce2YqVFseTHJpZm7JgwQL69+/f2mXscKod18YmOfSlKjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMrGC77747AMuXL2fUqFFV+xx77LFs7WsD11xzDevWrdv0ubWmandwmJm1kP32248pU6Zs8/qVwdFaU7UXGhySRkp6WtIiSeOrLB8u6XFJGyWNKms/TtLsstcGSaemZbdKeq5s2aAi98HMrNL48eO57rrrNn2+7LLLuPzyyxkxYgRDhgzh0EMP5b777ttivSVLljBw4EAA1q9fz5gxY+jfvz+nnXbaZvNVXXDBBZRKJQYMGMCll14KZJMnLl++nOOOO47jjjsOyKZqf/XVVwG46qqrGDhwIAMHDuSaa67Z9PP69+/Pl7/8ZQYMGMAJJ5ywXebFKmzKEUntgOuATwL1wExJUyNiflm3F4CxwHfK142I6cCgtJ3uwCLg92VdvhsR2x7bZrZjeGA8vPTk9t3mBw+FE69sssvo0aP55je/yde//nUAJk+ezLRp07jooovYY489ePXVVznyyCM5+eSTG32e9/XXX0/nzp1ZsGABc+bMYciQIZuWXXHFFXTv3p13332XESNGMGfOHC666CKuuuoqpk+fzt57773ZtmbNmsUtt9zCY489RkRwxBFH8PGPf5xu3boVMoV7kWccw4BFEbE4It4GJgGnlHeIiCURMQd4r4ntjAIeiIh1TfQxM2sxgwcP5pVXXmH58uU88cQTdOvWjQ9+8IN873vf47DDDuMTn/gEy5Yt4+WXX250G3/+8583/QI/7LDDOOywwzYtmzx5MkOGDGHw4MHMmzeP+fPnN7YZAB599FFOO+00unTpwu67787nPvc5HnnkEaCYKdyLnOSwF7C07HM9cMQ2bGcMcFVF2xWSfgj8ARgfEW9tW4lm1qZt5cygSKeffjpTpkzhpZdeYvTo0dx5552sWLGCWbNm0aFDB/r27Vt1SvWtee655/jpT3/KzJkz6datG2PHjt2m7TQoYgr3mh4cl7QvcCgwraz5EuBg4HCgO3BxI+uOk1QnqW7FihWF12pmO5fRo0czadIkpkyZwumnn86aNWvYZ5996NChA9OnT+f5559vcv3hw4dz1113ATB37lzmzJkDwOuvv06XLl3Yc889efnll3nggQc2rdPYlO7HHHMMv/71r1m3bh1vvvkm9957L8ccc8x23NvNFXnGsQzoU/a5d2rL4wzg3oh4p6EhIl5Mb9+SdAsV4yNl/SYCEyGbHTfnzzUza9KAAQNYu3YtvXr1Yt999+Wss87is5/9LIceeiilUomDDz64yfUvuOACzjvvPPr370///v0ZOnQoAB/96EcZPHgwBx98MH369OGoo47atM64ceMYOXIk++23H9OnT9/UPmTIEMaOHcuwYcMA+NKXvsTgwYMLe7JgYdOqS2oPPAOMIAuMmcAXImJelb63Ar+pHPCWNAO4JA2WN7TtGxEvKhtxuhrYEBFb3LFVztOqm+04PK16MWpiWvWI2AhcSHaZaQEwOSLmSZog6eRU1OGS6oHTgRslbQoVSX3Jzlj+VLHpOyU9CTwJ7A1cXtQ+mJnZlgp9AmBE3A/cX9H2w7L3M8kuYVVbdwnZAHtl+/Hbt0ozM8ujpgfHzcyq2RmeXNqS8h5PB4eZtSmdOnVi5cqVDo/tJCJYuXIlnTp1avY6hV6qMjPb3nr37k19fT2+zX776dSpE717Vx01qMrBYWZtSocOHejXr19rl7FT86UqMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5FBockkZKelrSIknjqywfLulxSRsljapY9q6k2ek1tay9n6TH0jZ/KWnXIvfBzMw2V1hwSGoHXAecCBwCnCnpkIpuLwBjgbuqbGJ9RAxKr5PL2n8CXB0RBwKvAedv9+LNzKxRRZ5xDAMWRcTiiHgbmAScUt4hIpZExBzgveZsUJKA44Epqek24NTtV7KZmW1NkcHRC1ha9rk+tTVXJ0l1kmZIagiHHsDqiNi4tW1KGpfWr1uxYkXe2s3MrBHtW7uAJhwQEcskfQj4o6QngTXNXTkiJgITAUqlUhRUo5nZTqfIM45lQJ+yz71TW7NExLL072LgYWAwsBLYS1JD4OXappmZvX9FBsdM4KB0F9SuwBhg6lbWAUBSN0kd0/u9gaOA+RERwHSg4Q6sc4H7tnvlZmbWqMKCI41DXAhMAxYAkyNinqQJkk4GkHS4pHrgdOBGSfPS6v2BOklPkAXFlRExPy27GPiWpEVkYx43FbUPZma2JWV/xO/YSqVS1NXVtXYZZmZtiqRZEVGqbPc3x83MLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxyKTQ4JI2U9LSkRZLGV1k+XNLjkjZKGlXWPkjS3yTNkzRH0uiyZbdKek7S7PQaVOQ+mJnZ5toXtWFJ7YDrgE8C9cBMSVMjYn5ZtxeAscB3KlZfB3wxIhZK2g+YJWlaRKxOy78bEVOKqt3MzBpXWHAAw4BFEbEYQNIk4BRgU3BExJK07L3yFSPimbL3yyW9AvQEVmNmZq2qyEtVvYClZZ/rU1sukoYBuwLPljVfkS5hXS2pYyPrjZNUJ6luxYoVeX+smZk1oqYHxyXtC9wBnBcRDWcllwAHA4cD3YGLq60bERMjohQRpZ49e7ZIvWZmO4Mig2MZ0Kfsc+/U1iyS9gB+C3w/ImY0tEfEi5F5C7iF7JKYmZm1kCKDYyZwkKR+knYFxgBTm7Ni6n8vcHvlIHg6C0GSgFOBudu1ajMza1JhwRERG4ELgWnAAmByRMyTNEHSyQCSDpdUD5wO3ChpXlr9DGA4MLbKbbd3SnoSeBLYG7i8qH0wM7MtKSJau4bClUqlqKura+0yzMzaFEmzIqJU2V7Tg+NmZlZ7HBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTQrOCR9Q9IeytyUpkI/oejizMys9jT3jONfI+J14ASgG3AOcGVhVZmZWc1qbnAo/XsScEdEzCtrMzOznUhzg2OWpN+TBcc0SV2B97ayjpmZ7YCa+yCn84FBwOKIWCepO3BecWWZmVmtau4Zx8eApyNitaSzgR8Aa4ory8zMalVzg+N6YJ2kjwLfJnsa3+2FVWVmZjWrucGxMbJpdE8B/isirgO6FleWmZnVquaOcayVdAnZbbjHSNoF6FBcWWZmVquae8YxGniL7PscL5E9BvY/C6vKzMxqVrOCI4XFncCekj4DbIgIj3GYme2EmjvlyBnA38ke8XoG8JikUUUWZmZmtam5YxzfBw6PiFcAJPUEHgKmFFWYmZnVpuaOcezSEBrJyhzrmpnZDqS5Zxy/kzQNuDt9Hg3cX0xJZmZWy5o7OP5dYCJwWHpNjIiLt7aepJGSnpa0SNL4KsuHpynaN1aOmUg6V9LC9Dq3rH2opCfTNq+V5MkWzcxaUHPPOIiIe4B7mttfUjvgOuCTQD0wU9LUiJhf1u0FYCzwnYp1uwOXAiUgyCZZnBoRr5F9i/3LwGNkZz0jgQeaW5eZmb0/TQaHpLVkv7i3WAREROzRxOrDgEURsThtaxLZN883BUdELEnLKmfa/RTwYESsSssfBEZKehjYIyJmpPbbgVNxcJiZtZgmgyMi3s+0Ir2ApWWf64Ej3se6vdKrvkr7FiSNA8YB7L///s38sWZmtjU77J1RETExIkoRUerZs2drl2NmtsMoMjiWAX3KPvdObe9n3WXp/bZs08zMtoMig2MmcJCkfpJ2BcYAU5u57jTgBEndJHUje9b5tIh4EXhd0pHpbqovAvcVUbyZmVVXWHBExEbgQrIQWABMjoh5kiZIOhlA0uGS6smmMrlR0ry07irgR2ThMxOY0DBQDnwN+L/AIrLngnhg3MysBSl7zMaOrVQqRV1dXWuXYWbWpkiaFRGlyvYddnDczMyK4eAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS6FBoekkZKelrRI0vgqyztK+mVa/pikvqn9LEmzy17vSRqUlj2cttmwbJ8i98HMzDZXWHBIagdcB5wIHAKcKemQim7nA69FxIHA1cBPACLizogYFBGDgHOA5yJidtl6ZzUsj4hXitoHMzPbUpFnHMOARRGxOCLeBiYBp1T0OQW4Lb2fAoyQpIo+Z6Z1zcysBhQZHL2ApWWf61Nb1T4RsRFYA/So6DMauLui7ZZ0merfqwQNAJLGSaqTVLdixYpt3QczM6tQ04Pjko4A1kXE3LLmsyLiUOCY9Dqn2roRMTEiShFR6tmzZwtUa2a2cygyOJYBfco+905tVftIag/sCawsWz6GirONiFiW/l0L3EV2SczMzFpIkcExEzhIUj9Ju5KFwNSKPlOBc9P7UcAfIyIAJO0CnEHZ+Iak9pL2Tu87AJ8B5mJmZi2mfVEbjoiNki4EpgHtgJsjYp6kCUBdREwFbgLukLQIWEUWLg2GA0sjYnFZW0dgWgqNdsBDwM+L2gczM9uS0h/4O7RSqRR1dXWtXYaZWZsiaVZElCrba3pw3MzMao+Dw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5FBockkZKelrSIknjqyzvKOmXafljkvqm9r6S1kuanV43lK0zVNKTaZ1rJanIfTAzs80VFhyS2gHXAScChwBnSjqkotv5wGsRcSBwNfCTsmXPRsSg9PpqWfv1wJeBg9JrZFH7YGZmWyryjGMYsCgiFkfE28Ak4JSKPqcAt6X3U4ARTZ1BSNoX2CMiZkREALcDp27/0s3MrDFFBkcvYGnZ5/rUVrVPRGwE1gA90rJ+kv4h6U+SjinrX7+VbZqZWYHat3YBjXgR2D8iVkoaCvxa0oA8G5A0DhgHsP/++xdQopnZzqnIM45lQJ+yz71TW9U+ktoDewIrI+KtiFgJEBGzgGeBf0n9e29lm6T1JkZEKSJKPXv23A67Y2ZmUGxwzAQOktRP0q7AGGBqRZ+pwLnp/SjgjxERknqmwXUkfYhsEHxxRLwIvC7pyDQW8kXgvgL3wczMKhR2qSoiNkq6EJgGtANujoh5kiYAdRExFbgJuEPSImAVWbgADAcmSHoHeA/4akSsSsu+BtwK7AY8kF5mZtZClN2ctGMrlUpRV1fX2mWYmbUpkmZFRKmy3d8cNzOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrkUGhySRkp6WtIiSeOrLO8o6Zdp+WOS+qb2T0qaJenJ9O/xZes8nLY5O732KXIfzMxsc+2L2rCkdsB1wCeBemCmpKkRMb+s2/nAaxFxoKQxwE+A0cCrwGcjYrmkgcA0oFfZemdFRF1RtZuZWeOKPOMYBiyKiMUR8TYwCTilos8pwG3p/RRghCRFxD8iYnlqnwfsJqljgbWamVkzFRkcvYClZZ/r2fysYbM+EbERWAP0qOjzeeDxiHirrO2WdJnq3yWp2g+XNE5SnaS6FStWvJ/9MDOzMjU9OC5pANnlq6+UNZ8VEYcCx6TXOdXWjYiJEVGKiFLPnj2LL9bMbCdRZHAsA/qUfe6d2qr2kdQe2BNYmT73Bu4FvhgRzzasEBHL0r9rgbvILomZmVkLKTI4ZgIHSeonaVdgDDC1os9U4Nz0fhTwx4gISXsBvwXGR8RfGjpLai9p7/S+A/AZYG6B+2BmZhUKC440ZnEh2R1RC4DJETFP0gRJJ6duNwE9JC0CvgU03LJ7IXAg8MOK2247AtMkzQFmk52x/LyofTAzsy0pIlq7hsKVSqWoq/Pdu2ZmeUiaFRGlLdp3huCQtAJ4fhtX35vseyVtiWsuXlurF1xzS2lrNTdV7wERscXdRTtFcLwfkuqqJW4tc83Fa2v1gmtuKW2t5m2pt6ZvxzUzs9rj4DAzs1wcHFs3sbUL2AauuXhtrV5wzS2lrdWcu16PcZiZWS4+4zAzs1wcHGZmlouDowlbexBVrZG0JD38arakmvzGo6SbJb0iaW5ZW3dJD0pamP7t1po1Vmqk5sskLSub2eCk1qyxkqQ+kqZLmi9pnqRvpPaaPNZN1Fuzx1lSJ0l/l/REqvk/Unu/9GC6RelBdbu2dq0Nmqj5VknPlR3nQU1ux2Mc1aUHUT1D2YOogDMrHkRVUyQtAUoRUbNfPpI0HHgDuD0iBqa2/wWsiogrU0B3i4iLW7POco3UfBnwRkT8tDVra4ykfYF9I+JxSV2BWcCpwFhq8Fg3Ue8Z1OhxTo906BIRb6S58x4FvkE2fdKvImKSpBuAJyLi+tastUETNX8V+E1ETGnOdnzG0bjmPIjKcoqIPwOrKprLH+h1G9kvjJrRSM01LSJejIjH0/u1ZPPF9aJGj3UT9dasyLyRPnZIrwCOJ3swHdTQMYYma87FwdG45jyIqtYE8Htlz2kf19rF5PCBiHgxvX8J+EBrFpPDhZLmpEtZNXHJpxpJfYHBwGO0gWNdUS/U8HGW1E7SbOAV4EHgWWB1muQVavD3RmXNEdFwnK9Ix/lqbeWJqw6OHcvRETEEOBH4errE0qZEdu20LVw/vR74MDAIeBH4361bTnWSdgfuAb4ZEa+XL6vFY12l3po+zhHxbkQMInve0DDg4FYuaasqa5Y0ELiErPbDge5Ak5cvHRyNa86DqGpK2UOuXiF7CFZbecjVy+kad8O17ldauZ6tioiX03/A98im9q+5Y52uYd8D3BkRv0rNNXusq9XbFo4zQESsBqYDHwP2UvZgOqjh3xtlNY9MlwojPaL7FrZynB0cjWvOg6hqhqQuaVARSV2AE2g7D7kqf6DXucB9rVhLszT88k1Oo8aOdRoEvQlYEBFXlS2qyWPdWL21fJwl9VT20Dkk7UZ2I80Csl/Go1K3mjnG0GjNT5X9MSGyMZkmj7PvqmpCuvXvGqAdcHNEXNHKJTVK0ofIzjIA2gN31WK9ku4GjiWbyvll4FLg18BkYH+y6e/PiIiaGYxupOZjyS6fBLAE+ErZ2EGrk3Q08AjwJPBeav4e2bhBzR3rJuo9kxo9zpIOIxv8bkf2R/jkiJiQ/i9OIrvk8w/g7PSXfKtrouY/Aj0BkT0k76tlg+hbbsfBYWZmefhSlZmZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg6zGiTpWEm/ae06zKpxcJiZWS4ODrP3QdLZ6fkGsyXdmCaQeyNNFDdP0h8k9Ux9B0makSaSu7dhwj5JB0p6KD0j4XFJH06b313SFElPSbozfasXSVcqe27FHEk1N9247fgcHGbbSFJ/YDRwVJo07l3gLKALUBcRA4A/kX3THOB24ApPzHwAAAFvSURBVOKIOIzsG9IN7XcC10XER4H/QTaZH2QzxH4TOAT4EHCUpB5kU28MSNu5vNi9NNuSg8Ns240AhgIz0zTVI8h+wb8H/DL1+QVwtKQ9gb0i4k+p/TZgeJpfrFdE3AsQERsiYl3q8/eIqE8T/M0G+gJrgA3ATZI+BzT0NWsxDg6zbSfgtogYlF4fiYjLqvTb1nl9yuc3ehdon57zMIzsQUGfAX63jds222YODrNt9wdglKR9YNPzvA8g+3/VMDvqF4BHI2IN8JqkY1L7OcCf0tPu6iWdmrbRUVLnxn5gel7FnhFxP/BvwEeL2DGzprTfehczqyYi5kv6AdlTF3cB3gG+DrxJ9oCcH5A972J0WuVc4IYUDIuB81L7OcCNkiakbZzexI/tCtwnqRPZGc+3tvNumW2VZ8c1284kvRERu7d2HWZF8aUqMzPLxWccZmaWi884zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHL5/zO7U8vcDvavAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxAKwT0X62EQ",
        "outputId": "bd3521aa-8d2c-41e4-ce73-9af1b287183c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['mean_absolute_error'], label='train')\n",
        "plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
        "plt.ylim(0.12, 0.26)\n",
        "plt.title('Mean absolute error')\n",
        "plt.ylabel('metrics')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwq6o12e62ET"
      },
      "source": [
        "測試數據的誤差百分比：用測試數據預測房屋價格並與答案計算誤差百分比。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pXrckh262EU",
        "outputId": "5b66bb7d-f4b2-4ced-a656-fb37a0ef6399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 載入模型\n",
        "model = keras.models.load_model('/app/lab2-logs/models/Best-model-1.h5')\n",
        "# 先將房屋價格取出\n",
        "y_test = np.array(test_data['price'])\n",
        "# 標準化數據\n",
        "test_data = (test_data - mean) / std\n",
        "# 將輸入數據存成Numpy 格式\n",
        "x_test = np.array(test_data.drop('price', axis='columns'))\n",
        "# 預測測試數據\n",
        "y_pred = model.predict(x_test)\n",
        "# 將預測結果轉換回來(因為訓練時的訓練目標也有經過標準化)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "# 計算平均的誤差百分比\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "# 顯示誤差百分比\n",
        "print(\"Model_1 Percentage Error: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_1 Percentage Error: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDdS4gu262EW"
      },
      "source": [
        "### TensorBoard 可視化工具"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id9FClNy62EX"
      },
      "source": [
        "# 這行指令可以幫助我們直接在jupyter notebook上顯示TensorBoard\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a6jznxns62Ec"
      },
      "source": [
        "%tensorboard --port 9530 --logdir /app/lab2-logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_xlBTzE62Ef"
      },
      "source": [
        "# 實驗二：過擬合問題\n",
        "\n",
        "### 方法一、減少網路權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "exnLSm5662Ef",
        "outputId": "4a1fcc9f-9a0e-43ab-c728-7566209f65f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = keras.Sequential(name='model-2')\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(21,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "\n",
        "model_2.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-2')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-2.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_2.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 27s - loss: 2.4924 - mean_absolute_error: 0.8881WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.2651s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.9318 - mean_absolute_error: 0.6234 - val_loss: 1.1104 - val_mean_absolute_error: 0.6527\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6351 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6384 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1102 - val_mean_absolute_error: 0.6531\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1094 - val_mean_absolute_error: 0.6574\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6386 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6348 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6383 - val_loss: 1.1096 - val_mean_absolute_error: 0.6559\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6381 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6348 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1103 - val_mean_absolute_error: 0.6531\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1102 - val_mean_absolute_error: 0.6532\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6352 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1094 - val_mean_absolute_error: 0.6574\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6386 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1103 - val_mean_absolute_error: 0.6528\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6355 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6381 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6553\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6384 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6386 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6382 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6351 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6352 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6559\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6385 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6387 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1103 - val_mean_absolute_error: 0.6531\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6381 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc2a1bbac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9bGkqub62Ej"
      },
      "source": [
        "### 加入L1或L2 正則化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "11OLybIw62Ej",
        "outputId": "c4cf6b2a-8b81-4d7f-aa81-e1a2be82a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3 = keras.Sequential(name='model-3')\n",
        "model_3.add(layers.Dense(64, \n",
        "                         kernel_regularizer=keras.regularizers.l2(0.001), \n",
        "                         activation='relu', input_shape=(21,)))\n",
        "model_3.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model_3.add(layers.Dense(1))\n",
        "\n",
        "model_3.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-3')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-3.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_3.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 10s - loss: 1.1976 - mean_absolute_error: 0.7815WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0975s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6248 - val_loss: nan - val_mean_absolute_error: 0.6572\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6592\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6523\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6511\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6516\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6588\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6603\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6395 - val_loss: nan - val_mean_absolute_error: 0.6509\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6346 - val_loss: nan - val_mean_absolute_error: 0.6579\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6566\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6358 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6575\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6382 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6358 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6574\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6387 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6382 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6351 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6571\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6352 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6351 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6566\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6383 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6532\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6531\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6531\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6532\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6533\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6386 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6353 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6383 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6352 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6567\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6391 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6535\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6535\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc2a07fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiVIpUl662En"
      },
      "source": [
        "### 加入 Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh_SElzT62En",
        "outputId": "dcf5f7d4-f48a-45ff-a787-13e67540df6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4 = keras.Sequential(name='model-4')\n",
        "model_4.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
        "model_4.add(layers.Dropout(0.3))\n",
        "model_4.add(layers.Dense(64, activation='relu'))\n",
        "model_4.add(layers.Dropout(0.3))\n",
        "model_4.add(layers.Dense(1))\n",
        "\n",
        "model_4.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-4')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-4.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_4.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 8s - loss: 1.1799 - mean_absolute_error: 0.8582WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0819s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.5601 - mean_absolute_error: 0.4822 - val_loss: 1.1143 - val_mean_absolute_error: 0.6445\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6339 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6352 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6352 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6355 - val_loss: 1.1095 - val_mean_absolute_error: 0.6568\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6553\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1102 - val_mean_absolute_error: 0.6531\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6381 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1095 - val_mean_absolute_error: 0.6568\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6355 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6532\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6384 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc29fc9828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rSnob0H62Eq"
      },
      "source": [
        "### 驗證正則化的效能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGz8tUTu62Eq"
      },
      "source": [
        "Test model 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6dX65jr62Er",
        "outputId": "5d2a963c-5f0e-4bca-de7b-885a1c0b4f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = keras.models.load_model('/app/lab2-logs/models/Best-model-2.h5')\n",
        "y_pred = model_2.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_2: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_2: 42.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUPq1ao62Eu"
      },
      "source": [
        "Test model 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwQD-0bG62Eu",
        "outputId": "f06fb0f2-288e-4eef-e5fc-78fae7bf0d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3 = keras.models.load_model('/app/lab2-logs/models/Best-model-3.h5')\n",
        "y_pred = model_3.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_3: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_3: 42.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzog1SE62Ex"
      },
      "source": [
        "Test model 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2_BHbpJ62Ey",
        "outputId": "e2c67fee-b8d4-4c17-fbcf-7957f3b480cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4 = keras.models.load_model('/app/lab2-logs/models/Best-model-4.h5')\n",
        "y_pred = model_4.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_4: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_4: 42.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1gSHi2n62E1",
        "outputId": "823b42d5-8f6a-4e91-ef4e-bb078495c4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.225.38.180"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw1rLap1zu05"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}